{
    "Number of runs": 5, 
    
    "Value discount (gamma)": 0.99, 
    "Number of training episodes": 100, 
    "Maximum steps in training episode (for train environment termination)": 10000000, 
    "Maximum steps in evaluation episode (for evaluation environment termination)": 100,
    "Number of evaluation episodes": 10,
    
    "Episode interval for evaluation": 5, 
    "Initial number of stored trajectories": 100,
    "Number of steps in a collected trajectory": 100,
    "Number of trajectories used for training per episode": 50,
    "Number of steps in a minibatch": 80,

    "Maximum unique NFE": 30000000,
    
    "Compute periodic returns": true,
    "Sample minibatch": false,
    "Continuous minibatch": false,
    "Buffer used": false,
    "Replay buffer capacity": 100000,
    "Normalize advantages": true,
    "Discrete actions": true,
    "Advantage discount (lambda)": 0.95,
    "Use new problem formulation": true,
    "Include weights in state": false,
    
    "Actor network layer units": [200, 300, 200],
    "Actor network dropout probabilities": [0.10, 0.15, 0.10],
    "Critic network layer units": [200, 200, 100],
    "Critic network dropout probabilities": [0.10, 0.10, 0.05],
    
    "Use clipping loss": true,
    "Clipping ratio threshold": 0.1,
    "Use Adaptive KL penalty loss": false,
    "KL target": 0.005,
    "Adaptive KL coefficient (beta)": 1,
    "Use entropy loss bonus": true,
    "Entropy coefficient": 1e-3,
    "Use early stopping for actor training": true,
    
    "Number of actor training iterations": 50,
    "Number of critic training iterations": 50,
    
    "Initial actor training learning rate": 1e-4,
    "Initial critic training learning_rate": 2e-4,
    "Learning rate decay rate": 0.95,
    "Learning rate decay steps (actor)": 1000,
    "Learning rate decay steps (critic)": 1000,
    "RMSprop optimizer rho": 0.9,
    "RMSprop optimizer momentum": 0.1,

    "Episode interval to save actor and critic networks": 5,
    
    "Savepath": "C:\\SEAK Lab\\SEAK Lab Github\\Heuristics in RL\\python\\keras-based\\results\\"
}